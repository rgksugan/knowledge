{"componentChunkName":"component---node-modules-gatsby-theme-kb-src-templates-topic-js","path":"/3-resources/books/non-fiction/Hands-On-Large-Language-Models","result":{"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\nfunction _extends() { return _extends = Object.assign ? Object.assign.bind() : function (n) { for (var e = 1; e < arguments.length; e++) { var t = arguments[e]; for (var r in t) ({}).hasOwnProperty.call(t, r) && (n[r] = t[r]); } return n; }, _extends.apply(null, arguments); }\nfunction _objectWithoutProperties(e, t) { if (null == e) return {}; var o, r, i = _objectWithoutPropertiesLoose(e, t); if (Object.getOwnPropertySymbols) { var n = Object.getOwnPropertySymbols(e); for (r = 0; r < n.length; r++) o = n[r], -1 === t.indexOf(o) && {}.propertyIsEnumerable.call(e, o) && (i[o] = e[o]); } return i; }\nfunction _objectWithoutPropertiesLoose(r, e) { if (null == r) return {}; var t = {}; for (var n in r) if ({}.hasOwnProperty.call(r, n)) { if (-1 !== e.indexOf(n)) continue; t[n] = r[n]; } return t; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"tags\": \"non-fiction\",\n  \"type\": \"book\",\n  \"author\": \"Jay Alammar\",\n  \"title\": \"Hands-On Large Language Models\",\n  \"sub-title\": \"Language Understanding and Generation\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"Hands-On Large Language Models\"), mdx(\"p\", null, \"by \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/Jay-Alammar\",\n    \"title\": \"Jay Alammar\"\n  }, \"[[Jay Alammar]]\"), \"\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/Maarten-Grootendorst\",\n    \"title\": \"Maarten Grootendorst\"\n  }, \"[[Maarten Grootendorst]]\"), \"\"), mdx(\"h2\", null, \"Highlights\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Embeddings are vector representations of data that attempt to capture its meaning.\")), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Language AI refers to a subfield of AI that focuses on developing technologies capable of understanding, processing, and generating human language.\")), mdx(\"h2\", null, \"Contents\"), mdx(\"h3\", null, \"Understanding Language Models\"), mdx(\"h4\", null, \"An Introduction to Large Language Models\"), mdx(\"h4\", null, \"Tokens and Embeddings\"), mdx(\"h2\", null, \"The Book in 3 Sentences\"), mdx(\"h2\", null, \"Who Should Read It?\"), mdx(\"h2\", null, \"My Top 3 Quotes\"), mdx(\"h2\", null, \"Abbreviations\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"RNN - Recurrent Neural Networks\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"LMM - Large Language Models\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"AI - Artificial Intelligence\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"NPC - Non Playable Characters\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"NLP - Natural Language Processing\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"BERT - Bidirectional Encoder Representations from Transformers\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"VRAM - Video Random Access Memory\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"GUI - Graphical User Interface\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"BPE - Byte Pair Encoding\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"NER - Named Entity Recognition\")), mdx(\"h2\", null, \"Datasets\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.cs.cornell.edu/~shuochen/lme/data_page.html\"\n  }, \"Playlist\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://huggingface.co/datasets/cornell-movie-review-data/rotten_tomatoes\"\n  }, \"rotten_tomatoes\"))), mdx(\"h2\", null, \"Papers\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/1706.03762\"\n  }, \"Attention Is All You Need\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/1409.0473\"\n  }, \"Neural Machine Translation by Jointly Learning to Align and Translate\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/cs/0110053\"\n  }, \"Machine Learning in Automated Text Categorization\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/1908.10084\"\n  }, \"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf\"\n  }, \"Noise-contrastive estimation: A new estimation principle for unnormalized statistical models\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/1301.3781\"\n  }, \"Efficient Estimation of Word Representations in Vector Space\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/2111.09543\"\n  }, \"DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/2211.09085\"\n  }, \"Galactica: A Large Language Model for Science\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/2402.19173\"\n  }, \"StarCoder 2 and The Stack v2: The Next Generation\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/2305.06161\"\n  }, \"StarCoder: may the source be with you!\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/2207.14255\"\n  }, \"Efficient Training of Language Models to Fill in the Middle\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/1810.04805\"\n  }, \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf\"\n  }, \"Language Models are Unsupervised Multitask Learners\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/2005.14165\"\n  }, \"Language Models are Few-Shot Learners\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/2303.08774\"\n  }, \"GPT-4 Technical Report\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/2312.00752\"\n  }, \"Mamba: Linear-Time Sequence Modeling with Selective State Spaces\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/2305.13048\"\n  }, \"RWKV: Reinventing RNNs for the Transformer Era\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/2307.09288\"\n  }, \"Llama 2: Open Foundation and Fine-Tuned Chat Models\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/2404.14219\"\n  }, \"Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/2103.06874\"\n  }, \"CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/2105.13626\"\n  }, \"ByT5: Towards a Token-Free Future with Pre-trained Byte-to-Byte Models\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/37842.pdf\"\n  }, \"JAPANESE AND KOREAN VOICE SEARCH\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/1508.07909\"\n  }, \"Neural Machine Translation of Rare Words with Subword Units\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/1808.06226\"\n  }, \"SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/pdf/1804.10959\"\n  }, \"Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates\"))), mdx(\"h2\", null, \"Bibliography\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Designing Large Language Model Applications\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"Hands-On Large Language Models","private":false},"tableOfContents":{"items":[{"url":"#hands-on-large-language-models","title":"Hands-On Large Language Models","items":[{"url":"#highlights","title":"Highlights"},{"url":"#contents","title":"Contents","items":[{"url":"#understanding-language-models","title":"Understanding Language Models","items":[{"url":"#an-introduction-to-large-language-models","title":"An Introduction to Large Language Models"},{"url":"#tokens-and-embeddings","title":"Tokens and Embeddings"}]}]},{"url":"#the-book-in-3-sentences","title":"The Book in 3 Sentences"},{"url":"#who-should-read-it","title":"Who Should Read It?"},{"url":"#my-top-3-quotes","title":"My Top 3 Quotes"},{"url":"#abbreviations","title":"Abbreviations"},{"url":"#datasets","title":"Datasets"},{"url":"#papers","title":"Papers"},{"url":"#bibliography","title":"Bibliography"}]}]},"outboundReferences":[],"inboundReferences":[{"contextLine":"- [[Hands-On Large Language Models]]","referrer":{"parent":{"id":"3510e059-a883-51ed-8ab3-b83280cd105a","fields":{"slug":"/3-resources/books/non-fiction/Index","title":"Non-Fiction Books Index"}}}}]},"fields":{"slug":"/3-resources/books/non-fiction/Hands-On-Large-Language-Models","title":"Hands-On Large Language Models"}}},"pageContext":{"id":"2fc2127d-cb00-5044-957c-f61b6661df1a","refWordMdxSlugDict":{},"tocTypes":["sidebar"]}},"staticQueryHashes":["2221750479","2380733210","2768355698","63159454","847517413"]}