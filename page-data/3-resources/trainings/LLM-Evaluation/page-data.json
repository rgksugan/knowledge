{"componentChunkName":"component---node-modules-gatsby-theme-kb-src-templates-topic-js","path":"/3-resources/trainings/LLM-Evaluation","result":{"data":{"file":{"childMdx":{"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"LLM Evaluation\"), mdx(\"h2\", null, \"Introduction to LLM Evaluation\"), mdx(\"p\", null, \"Metrics\\nQualitiative\\nQuantitative\"), mdx(\"h2\", null, \"Task-specific Evaluation\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"LLM tasks\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Natural Language Understanding (NLU)\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Intent classification\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Named Entity Recognition (NER)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Sentiment analysis\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Goal\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Metrics -> accuracy, precision, recall, F1 score\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Benchmarks -> GLUE\"))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Question Answering (QA)\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Extractive -> is available in the book -> F1 score\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Abstrative -> ROGUE, BERT Score\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Open domain\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Goal\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Metrics\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Benchmarks\"))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Summarization\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Extractive\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Abstractive\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Machine Translation\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Code generation\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Reasoning\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Agentic Behavior\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Custom tasks\")))), mdx(\"h2\", null, \"Evaluation Metrics\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Quantitative\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Mostly needs labeled dataset\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Examples: Accuracy, F1, Perplexity, BLEU, ROGUE, BERT etc\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"BLEU\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Bilinigual Evaluation Understudy\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Two types\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Statistical\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"F1, Precision, recall, accuracy, perplexity, hit rate\"))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Model based\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"BERT scroe, MoverScore\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"GPTScore, SelfCheckGPT, QAG Score, LLM based BLEU/ROGUE\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"NLI, BLEURT\"))))))), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Qualitiative\", mdx(\"ul\", {\n    parentName: \"li\"\n  }, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Fluency, relevance, coherence\")))), mdx(\"h2\", null, \"Evaluation Methods and Resources\"), mdx(\"h2\", null, \"Common Pitfalls and Best Practices\"), mdx(\"h2\", null, \"Abbreviations\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"RAG - Retrieval Augmented Generation\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"BLEU - BiLinigual Evaluation Understudy\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"NER - Named Entity Recognition\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"QA - Quesiton Answering\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"GLUE - General Language Understanding Evaluation\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"NLI - Natural Language Interference\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"MBPP - Mostly Basic Python Problems\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"APPS - Automated Programming Progress Standard\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"MRR - Mean Reciprocal Rank\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"NDCG - Nomalized Discounted Cumulative Gain\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"AST - Abstract Syntax Trees\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"","private":false},"tableOfContents":{"items":[{"url":"#llm-evaluation","title":"LLM Evaluation","items":[{"url":"#introduction-to-llm-evaluation","title":"Introduction to LLM Evaluation"},{"url":"#task-specific-evaluation","title":"Task-specific Evaluation"},{"url":"#evaluation-metrics","title":"Evaluation Metrics"},{"url":"#evaluation-methods-and-resources","title":"Evaluation Methods and Resources"},{"url":"#common-pitfalls-and-best-practices","title":"Common Pitfalls and Best Practices"},{"url":"#abbreviations","title":"Abbreviations"}]}]},"outboundReferences":[],"inboundReferences":[]},"fields":{"slug":"/3-resources/trainings/LLM-Evaluation","title":"LLM Evaluation"}}},"pageContext":{"id":"38c18f59-1eef-575f-840c-466fe79e6e90","refWordMdxSlugDict":{},"tocTypes":["sidebar"]}},"staticQueryHashes":["2221750479","2380733210","2768355698","63159454","847517413"]}